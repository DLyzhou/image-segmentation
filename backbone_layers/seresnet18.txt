0: data (?, 512, 512, 3)
1: bn_data (?, 512, 512, 3)
2: zero_padding2d_1 (?, 518, 518, 3)
3: conv0 (?, 256, 256, 64)
4: bn0 (?, 256, 256, 64)
5: relu0 (?, 256, 256, 64)
6: zero_padding2d_2 (?, 258, 258, 64)
7: pooling0 (?, 128, 128, 64)
8: stage1_unit1_bn1 (?, 128, 128, 64)
9: stage1_unit1_relu1 (?, 128, 128, 64)
10: zero_padding2d_3 (?, 130, 130, 64)
11: stage1_unit1_conv1 (?, 128, 128, 64)
12: stage1_unit1_bn2 (?, 128, 128, 64)
13: stage1_unit1_relu2 (?, 128, 128, 64)
14: zero_padding2d_4 (?, 130, 130, 64)
15: stage1_unit1_conv2 (?, 128, 128, 64)
16: lambda_1 (?, 1, 1, 64)
17: conv2d_1 (?, 1, 1, 4)
18: activation_1 (?, 1, 1, 4)
19: conv2d_2 (?, 1, 1, 64)
20: activation_2 (?, 1, 1, 64)
21: multiply_1 (?, 128, 128, 64)
22: stage1_unit1_sc (?, 128, 128, 64)
23: add_1 (?, 128, 128, 64)
24: stage1_unit2_bn1 (?, 128, 128, 64)
25: stage1_unit2_relu1 (?, 128, 128, 64)
26: zero_padding2d_5 (?, 130, 130, 64)
27: stage1_unit2_conv1 (?, 128, 128, 64)
28: stage1_unit2_bn2 (?, 128, 128, 64)
29: stage1_unit2_relu2 (?, 128, 128, 64)
30: zero_padding2d_6 (?, 130, 130, 64)
31: stage1_unit2_conv2 (?, 128, 128, 64)
32: lambda_2 (?, 1, 1, 64)
33: conv2d_3 (?, 1, 1, 4)
34: activation_3 (?, 1, 1, 4)
35: conv2d_4 (?, 1, 1, 64)
36: activation_4 (?, 1, 1, 64)
37: multiply_2 (?, 128, 128, 64)
38: add_2 (?, 128, 128, 64)
39: stage2_unit1_bn1 (?, 128, 128, 64)
40: stage2_unit1_relu1 (?, 128, 128, 64)
41: zero_padding2d_7 (?, 130, 130, 64)
42: stage2_unit1_conv1 (?, 64, 64, 128)
43: stage2_unit1_bn2 (?, 64, 64, 128)
44: stage2_unit1_relu2 (?, 64, 64, 128)
45: zero_padding2d_8 (?, 66, 66, 128)
46: stage2_unit1_conv2 (?, 64, 64, 128)
47: lambda_3 (?, 1, 1, 128)
48: conv2d_5 (?, 1, 1, 8)
49: activation_5 (?, 1, 1, 8)
50: conv2d_6 (?, 1, 1, 128)
51: activation_6 (?, 1, 1, 128)
52: multiply_3 (?, 64, 64, 128)
53: stage2_unit1_sc (?, 64, 64, 128)
54: add_3 (?, 64, 64, 128)
55: stage2_unit2_bn1 (?, 64, 64, 128)
56: stage2_unit2_relu1 (?, 64, 64, 128)
57: zero_padding2d_9 (?, 66, 66, 128)
58: stage2_unit2_conv1 (?, 64, 64, 128)
59: stage2_unit2_bn2 (?, 64, 64, 128)
60: stage2_unit2_relu2 (?, 64, 64, 128)
61: zero_padding2d_10 (?, 66, 66, 128)
62: stage2_unit2_conv2 (?, 64, 64, 128)
63: lambda_4 (?, 1, 1, 128)
64: conv2d_7 (?, 1, 1, 8)
65: activation_7 (?, 1, 1, 8)
66: conv2d_8 (?, 1, 1, 128)
67: activation_8 (?, 1, 1, 128)
68: multiply_4 (?, 64, 64, 128)
69: add_4 (?, 64, 64, 128)
70: stage3_unit1_bn1 (?, 64, 64, 128)
71: stage3_unit1_relu1 (?, 64, 64, 128)
72: zero_padding2d_11 (?, 66, 66, 128)
73: stage3_unit1_conv1 (?, 32, 32, 256)
74: stage3_unit1_bn2 (?, 32, 32, 256)
75: stage3_unit1_relu2 (?, 32, 32, 256)
76: zero_padding2d_12 (?, 34, 34, 256)
77: stage3_unit1_conv2 (?, 32, 32, 256)
78: lambda_5 (?, 1, 1, 256)
79: conv2d_9 (?, 1, 1, 16)
80: activation_9 (?, 1, 1, 16)
81: conv2d_10 (?, 1, 1, 256)
82: activation_10 (?, 1, 1, 256)
83: multiply_5 (?, 32, 32, 256)
84: stage3_unit1_sc (?, 32, 32, 256)
85: add_5 (?, 32, 32, 256)
86: stage3_unit2_bn1 (?, 32, 32, 256)
87: stage3_unit2_relu1 (?, 32, 32, 256)
88: zero_padding2d_13 (?, 34, 34, 256)
89: stage3_unit2_conv1 (?, 32, 32, 256)
90: stage3_unit2_bn2 (?, 32, 32, 256)
91: stage3_unit2_relu2 (?, 32, 32, 256)
92: zero_padding2d_14 (?, 34, 34, 256)
93: stage3_unit2_conv2 (?, 32, 32, 256)
94: lambda_6 (?, 1, 1, 256)
95: conv2d_11 (?, 1, 1, 16)
96: activation_11 (?, 1, 1, 16)
97: conv2d_12 (?, 1, 1, 256)
98: activation_12 (?, 1, 1, 256)
99: multiply_6 (?, 32, 32, 256)
100: add_6 (?, 32, 32, 256)
101: stage4_unit1_bn1 (?, 32, 32, 256)
102: stage4_unit1_relu1 (?, 32, 32, 256)
103: zero_padding2d_15 (?, 34, 34, 256)
104: stage4_unit1_conv1 (?, 16, 16, 512)
105: stage4_unit1_bn2 (?, 16, 16, 512)
106: stage4_unit1_relu2 (?, 16, 16, 512)
107: zero_padding2d_16 (?, 18, 18, 512)
108: stage4_unit1_conv2 (?, 16, 16, 512)
109: lambda_7 (?, 1, 1, 512)
110: conv2d_13 (?, 1, 1, 32)
111: activation_13 (?, 1, 1, 32)
112: conv2d_14 (?, 1, 1, 512)
113: activation_14 (?, 1, 1, 512)
114: multiply_7 (?, 16, 16, 512)
115: stage4_unit1_sc (?, 16, 16, 512)
116: add_7 (?, 16, 16, 512)
117: stage4_unit2_bn1 (?, 16, 16, 512)
118: stage4_unit2_relu1 (?, 16, 16, 512)
119: zero_padding2d_17 (?, 18, 18, 512)
120: stage4_unit2_conv1 (?, 16, 16, 512)
121: stage4_unit2_bn2 (?, 16, 16, 512)
122: stage4_unit2_relu2 (?, 16, 16, 512)
123: zero_padding2d_18 (?, 18, 18, 512)
124: stage4_unit2_conv2 (?, 16, 16, 512)
125: lambda_8 (?, 1, 1, 512)
126: conv2d_15 (?, 1, 1, 32)
127: activation_15 (?, 1, 1, 32)
128: conv2d_16 (?, 1, 1, 512)
129: activation_16 (?, 1, 1, 512)
130: multiply_8 (?, 16, 16, 512)
131: add_8 (?, 16, 16, 512)
132: bn1 (?, 16, 16, 512)
133: relu1 (?, 16, 16, 512)
